# -*- coding: utf-8 -*-
"""scrape_files.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1oVTaSw1cI_bqOEBc4u90TVKanU2YMzoE
"""

import xml.etree.ElementTree as ET
import datetime
import time
import sys
from urllib.parse import urlencode
from urllib.request import urlopen
from urllib.error import HTTPError
import pandas as pd

tree1 = ET.parse('/content/query.xml')

root1 = tree1.getroot()

for child in root1:
  # print("Tag: ")
  print (child.tag)
  # print("\t Attribute: ")
  print(child.attrib)

newURL = '{http://arxiv.org/OAI/arXiv/}'
W3 = '{http://www.w3.org/2005/Atom}'
A9 = '{http://a9.com/-/spec/opensearch/1.1/}'
myBASE = 'http://export.arxiv.org/api/query?'

url = 'http://export.arxiv.org/api/query?search_query=all:network'
response = urlopen(url)
xml = response.read()

root = ET.fromstring(xml)
records = root.findall(W3 + 'entry')

root.tag

print(records)

field = ['id','url','summary','title','author','updated']
  # with open('scrape.csv', 'w') as csvfile:
  #   writer = csv.DictWriter(csvfile, fieldnames=field)
  #   writer.writeheader()
  #   writer.writerows(dict)
df_op = pd.DataFrame()
# print(output.head())
for record in records:
  meta = Record(record).output()
  df_op = df_op.append(meta, ignore_index=True)


df_op.to_csv("scrape.csv",index=False)

class Record(object):

  def __init__(self, xml_file):
    self.xml = xml_file
    self.id = self._get_text(W3, 'id')
    self.summary = self._get_text(W3, 'summary')
    self.title = self._get_text(W3, 'title')
    self.author = self._get_authors()
    self.updated = self._get_year()
    # self.updated = self._get_text(W3, 'updated')

  def _get_text(self, namespace, tag):
    try:
      return self.xml.find(namespace + tag).text.strip().lower().replace('\n','.')
    except:
      return ''

  def _get_name(self, parent, attribute):
    try: 
      return parent.find(W3 + attribute).text.lower()
    except:
      return "n/a"

  def _get_authors(self):
    authors_xml = self.xml.findall(W3 + 'author')
    names = [self._get_name(author, 'name') for author in authors_xml]
    # first_names = [self._get_name(author, 'forenames') for author in authors_xml]
    # full_names = [a+' '+b for a,b in zip(first_names, last_names)]
    return names

  def _get_year(self):
    updated_year = self._get_text(W3, 'updated')
    year = updated_year[0:4]
    return year

  def output(self):
    dict = {
        'id' : self.id,
        'summary' : self.summary,
        'title' : self.title,
        'author' : self.author,
        'updated': self.updated
    }
    return dict

